"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[339],{3905:(e,t,n)=>{n.d(t,{Zo:()=>s,kt:()=>f});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var c=r.createContext({}),p=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},s=function(e){var t=p(e.components);return r.createElement(c.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},g=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,c=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),u=p(n),g=a,f=u["".concat(c,".").concat(g)]||u[g]||m[g]||o;return n?r.createElement(f,i(i({ref:t},s),{},{components:n})):r.createElement(f,i({ref:t},s))}));function f(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=g;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l[u]="string"==typeof e?e:a,i[1]=l;for(var p=2;p<o;p++)i[p]=n[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}g.displayName="MDXCreateElement"},5083:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>c,default:()=>f,frontMatter:()=>l,metadata:()=>p,toc:()=>u});n(7294);var r=n(3905);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))})),e}function i(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}const l={sidebar_position:2},c="Quickstart: LangChainGo with OpenAI",p={unversionedId:"getting-started/guide-openai",id:"getting-started/guide-openai",title:"Quickstart: LangChainGo with OpenAI",description:"Dive right into executing your first program utilizing LangChainGo in tandem with OpenAI. OpenAI's GPT models are renowned for their proficiency and expansive capabilities.",source:"@site/docs/getting-started/guide-openai.mdx",sourceDirName:"getting-started",slug:"/getting-started/guide-openai",permalink:"/langchaingo/docs/getting-started/guide-openai",draft:!1,editUrl:"https://github.com/tmc/langchaingo/edit/main/docs/docs/getting-started/guide-openai.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"sidebar",previous:{title:"Quickstart: LangChainGo with Ollama",permalink:"/langchaingo/docs/getting-started/guide-ollama"},next:{title:"Agents",permalink:"/langchaingo/docs/modules/agents/agents/"}},s={},u=[{value:"Pre-requisites",id:"pre-requisites",level:2},{value:"Steps",id:"steps",level:2}],m={toc:u},g="wrapper";function f(e){var{components:t}=e,n=i(e,["components"]);return(0,r.kt)(g,o(function(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{},r=Object.keys(n);"function"==typeof Object.getOwnPropertySymbols&&(r=r.concat(Object.getOwnPropertySymbols(n).filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable})))),r.forEach((function(t){a(e,t,n[t])}))}return e}({},m,n),{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"quickstart-langchaingo-with-openai"},"Quickstart: LangChainGo with OpenAI"),(0,r.kt)("p",null,"Dive right into executing your first program utilizing LangChainGo in tandem with ",(0,r.kt)("a",{parentName:"p",href:"https://openai.com/"},"OpenAI"),". OpenAI's GPT models are renowned for their proficiency and expansive capabilities."),(0,r.kt)("h2",{id:"pre-requisites"},"Pre-requisites"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"OpenAI API Key"),": Sign up on ",(0,r.kt)("a",{parentName:"li",href:"https://openai.com/"},"OpenAI")," and retrieve your API key."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Go"),": ",(0,r.kt)("a",{parentName:"li",href:"https://go.dev/doc/install"},"Download and install Go"),".")),(0,r.kt)("h2",{id:"steps"},"Steps"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Set up your OpenAI API Key"),": Before interacting with the OpenAI API, ensure that you've set up your API key. Typically, this is done by setting an environment variable. In your terminal, run the command:",(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"export OPENAI_API_KEY=your_openai_api_key_here\n")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"\n2. Run the Example: Execute the following command:\n\n```shell\ngo run github.com/tmc/langchaingo/examples/openai-completion-example@main\n")),(0,r.kt)("p",null,"Anticipate an output similar to the one below:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"The first man to walk on the moon was Neil\n")),(0,r.kt)("p",null,"Congratulations! You've successfully built and executed your first LangChainGo LLM-backed program using OpenAI's cloud-based inference."),(0,r.kt)("p",null,"Here is the entire program (from ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/tmc/langchaingo/blob/main/examples/ollama-chat-example/ollama_chat_example.go"},"ollama-chat-example"),")."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-go"},'package main\n\nimport (\n    "context"\n    "fmt"\n    "log"\n\n    "github.com/tmc/langchaingo/llms"\n    "github.com/tmc/langchaingo/llms/openai"\n)\n\nfunc main() {\n    llm, err := openai.New()\n    if err != nil {\n        log.Fatal(err)\n    }\n    ctx := context.Background()\n    completion, err := llm.Call(ctx, "The first man to walk on the moon",\n        llms.WithTemperature(0.8),\n        llms.WithStopWords([]string{"Armstrong"}),\n    )\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    fmt.Println(completion)\n}\n')))}f.isMDXComponent=!0}}]);